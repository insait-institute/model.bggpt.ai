<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <title>State-of-the-art Bulgarian LLMs</title>
    <link rel="icon" type="image/png" href="/assets/img/icon.144.png">
    <link rel="canonical" href="https://models.bggpt.ai/blog/2024-02-18-launching-the-first-free-and-open-bulgarian-llm/">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/css/bootstrap.min.css" rel="stylesheet"
      integrity="sha384-iYQeCzEYFbKjA/T2uDLTpkwGzCiq6soy8tYaI1GyVh/UjpbCx/TYkiZhlZB6+fzT" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"
      integrity="sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL"
      crossorigin="anonymous"></script>
    <link rel="stylesheet" href="/assets/css/style.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.0/jquery.min.js"></script>

    <script>
	  $(document).ready(function () {
		if (history.scrollRestoration) {
			history.scrollRestoration = 'manual';
		}
	  });
      function handleLanguageChange(cb) {
        if (cb.checked) {
          document.body.classList.remove('lang-bg');
          document.body.classList.add('lang-en');
          localStorage.setItem('lang', 'en');
        }
        else {
          document.body.classList.remove('lang-en');
          document.body.classList.add('lang-bg');
          localStorage.setItem('lang', 'bg');
        }
      }
      function handleThemeChange() {
        document.body.classList.toggle('dark')
        if ($('body').hasClass('dark')) {
          localStorage.setItem('color', 'dark');
        }
        else {
          localStorage.setItem('color', 'light');
        }
      }
      $(document).ready(function () {
        console.log(localStorage.getItem('lang'))
        if (localStorage.getItem('lang') === "en"){
          document.body.classList.remove('lang-bg');
          document.body.classList.add('lang-en');
          $('.lang-switch input.check-toggle-round-flat').prop( "checked", true );
        }
        else {
          document.body.classList.remove('lang-en');
          document.body.classList.add('lang-bg');
          $('.lang-switch input.check-toggle-round-flat').prop( "checked", false );
        }
        if (localStorage.getItem('color') === "dark"){
          document.body.classList.add('dark');
        }
        else {
          document.body.classList.remove('dark');
        }
      });
	  $(document).ready(function () {
		if (history.scrollRestoration) {
			history.scrollRestoration = 'manual';
		}
	  });
    </script>

    <meta name="description" content="State-of-the-art generative AI created for the Bulgarian government, users, public and private organizations" />
    <meta name="keywords" content="Bulgaria, LLM, BgGPT, BgGPT-Gemma-2-2.6B-IT-v1.0, BgGPT-Gemma-2-9B-IT-v1.0, BgGPT-Gemma-2-27B-IT-v1.0, BgGPT-Gemma-2, AI, Chatbot, Open-source, Open">
    <meta property="og:title" content="State-of-the-art Bulgarian LLMs" />
    <meta property="og:description" content="State-of-the-art generative AI created for the Bulgarian government, users, public and private organizations" />
    <meta property="og:image" content="https://models.bggpt.ai/assets/img/social_en.png" />
    <meta property="og:url" content="https://models.bggpt.ai/blog/"/>
    <meta property="og:type" content="website" />
    <meta name="twitter:description" content="State-of-the-art generative AI created for the Bulgarian government, users, public and private organizations" />
    <meta name="twitter:image" content="https://models.bggpt.ai/assets/img/social_en.png" />
    <meta name="twitter:image:src" content="https://models.bggpt.ai/assets/img/social_en.png" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="State-of-the-art Bulgarian LLMs" />
  </head>

  <body>
    <nav class="navbar navbar-expand-lg fixed-top">
      <div class="nav-bar-stipe"></div>
      <div class="container">
        <a class="navbar-brand navbar-text" href="/">
          <img src="/assets/img/logo_white2.svg" class="d-inline-block align-top light-only" alt="Logo of the website">
          <img src="/assets/img/logo_black2.svg" class="d-inline-block align-top dark-only" alt="Logo of the website">
        </a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav"
          aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse offset-sm-6 offset-lg-0" id="navbarNav">
          <ul class="navbar-nav bg-custom ms-auto">
            <li class="nav-item">
              <a class="nav-link" href="https://insait.ai/" >За INSAIT</a>
              <a class="nav-link" href="https://insait.ai/" lang="en">About INSAIT</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="https://chat.bggpt.ai/" >BgGPT чат</a>
              <a class="nav-link" href="https://chat.bggpt.ai/" lang="en">BgGPT chat</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="/blog/" lang="en">Blog</a>
              <a class="nav-link" href="/blog/" >Блог</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="https://huggingface.co/INSAIT-Institute" lang="en">INSAIT models</a>
              <a class="nav-link" href="https://huggingface.co/INSAIT-Institute" >Модели на INSAIT</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="mailto:bggpt@insait.ai" lang="en">Contact us</a>
              <a class="nav-link" href="mailto:bggpt@insait.ai" >Свържи се с нас</a>
            </li>
            <li class="nav-item toggle">
              <button class="light-switch" onclick="handleThemeChange();">
                <span class="on"><img src="/assets/img/sun.svg" width="20" height="20" alt="Icon for brightness"></span>
                <span class="off"><img src="/assets/img/moon.svg" width="20" height="20" alt="Icon for brightness"></span>
              </button>
            </li>
            <li class="nav-item">
              <div class="lang-switch">
                <input id="language-toggle" class="check-toggle check-toggle-round-flat" type="checkbox"
                  onclick="handleLanguageChange(this)">
                <label for="language-toggle"></label>
                <span class="on">БГ</span>
                <span class="off">EN</span>
              </div>
            </li>
          </ul>
        </div>
      </div>
    </nav>
	
   <div class="container">
 	  <h1 style="margin-bottom:0;"  id="blogen2">INSAIT с нови езикови модели за български, установявайки нов стандарт за големи езикови модели на национално ниво</h1>
	  <p class="date" style="margin-top:1rem;font-size:155%;color:gray;" >За пръв път отворени езикови модели с практичен размер за конкретен език надминават по ефективност много по-големи отворени модели, като същевременно са конкурентоспособни за чат с платени платформи като OpenAI и Anthropic.</p>
	  <p class="date" style="margin-bottom:2rem;font-size:110%;"  >19 ноември 2024 г</p>
	  

      <p lang="en" >INSAIT is delighted to announce the release of three new state-of-the-art AI models, a 27 billion, a 9 billion, and a small 2.6 billion parameter models,
	  targeting the Bulgarian language (called BgGPT). The 27B and 9B models demonstrate unprecedented performance in Bulgarian, outpacing much larger ones,
	  while retaining English language capabilities. Beyond benchmarks, INSAIT’s 27B model significantly surpasses GPT-4o-mini and rivals GPT-4o in Bulgarian chat performance,
	  according to GPT-4o itself used as a judge. We observe similar results with Anthropic’s Claude Haiku and Sonnet paid models.</p>
      <p >INSAIT обявява пускането на три нови AI модела на световно ниво -  27 милиарден (BgGPT 27B), 9 милиарден (BgGPT 9B) и малък модел с 2.6 милиарда параметъра (BgGPT 2.6B), специално за български език. 
	  Моделите BgGPT 27B и 9B демонстрират безпрецедентни резултати върху български тестове, надминавайки много по-големи модели, като същевременно запазват способностите си на английски език. 
	  Отвъд резултатите на тестовете за  български, допълнително тествахме и способностите на моделите за чат. 
	  Според самия GPT-4o, използван като съдия, BgGPT 27B значително надминава GPT-4o-mini и се конкурира с GPT-4o при чат на български. 
	  Наблюдаваме подобни резултати с платените модели на Anthropic – Claude Haiku и Claude Sonnet.</p>

	  <p >Моделите на INSAIT са базирани на семейството от отворени модели на Google – Gemma 2 и са обучени на около 100 милиарда токена (85 млрд. от тях на български). 
	  Обучението е извършено с помощта иновативен метод, основан на сливане на модели, който INSAIT изобрети, описа и представи на <a href="#ref-emnlp-19-nov">EMNLP’24 [1]</a>. 
	  Допълнително моделите са специално настроени, използвайки български набор от данни с инструкции от чат приложението <a href="https://chat.bggpt.ai/">https://chat.bggpt.ai/</a>. </p>
	  
	  <br><br>
	  <h2  >Справяне с катастрофално забравяне чрез разклоняване и сливане</h2>
	  
	  <div style="display: flex; justify-content: center;align-items: center;max-width:100%"><object type="image/svg+xml" style="max-width:100%;padding-top:50pt; padding-bottom:50pt;" data="/assets/img/bggpt_merge_nov19.svg"></object></div>
	  
	  <p >Ключът към ефективността на новите модели BgGPT е алгоритъмът за разклоняване и сливане, който беше представен на <a href="#ref-emnlp-19-nov">EMNLP’24 [1]</a>. 
	  Този метод позволява на модела да научава <b>нови умения</b> (например български език), като същевременно <b>запазва старите</b> (например английски език, математика или “few-shot” способности), 
	  налични в <b>основния модел</b> (в случая Gemma-2).</p>

	  <p >В основни линии методът работи като разделя тренировъчните данни на няколко части (обозначени с G в горната фигура) и тренира отделни модели на всеки един от тях, които след това се сливат, за да се получи крайният модел. 
	  С помощта на този метод, до голяма степен се избягва катастрофалното забравяне, което обикновено се случва при обучението на само един модел.</p>
	  <p >Процесът на разработка на моделите BgGPT се състои от поредица от сливания на модели, както е демонстрирано в горната фигура, където показваме първия етап на тренирането - непрекъснатото дообучение. 
	  Следва етап на обучение върху български набор от данни с инструкции от 	чат приложението. Отбелязваме, че методологията ни е общоприложима и може да бъде използвана както за български, 
	  така и за други езици, както и се описва в <a href="#ref-emnlp-19-nov">статията ни [1]</a>.</p>
	  
	  <br><br>
	  <h2 >Тестове на български и английски език</h2>
	  
	  <p >Анализирахме способностите на моделите върху набор от стандартни тестове на английски, техни преводи на български, както и специфични тестове на български, които сме събрали:</p>
	  
      <ul>
        <li ><b><a href="#ref-winograde-19-nov">Winogrande challenge [2]</a>:</b> тества общи познания и разбиране</li>
        <li ><b><a href="#ref-hellaswag-19-nov">Hellaswag [3]</a>:</b> тества способността за довършване на изречения</li>
        <li ><b><a href="#ref-arc-challenge-19-nov">ARC Easy/Challenge [4]</a>:</b> тества логически разсъждения</li>
		<li ><b><a href="#ref-triviaqa-19-nov">TriviaQA [5]</a>:</b> тества фактологични знания</li>
        <li ><b><a href="#ref-gsm8k-19-nov">GSM-8K [6]</a>:</b> тества въпроси по математика на гимназиално ниво с множествен избор на отговора</li>
		<li ><b><a href="#ref-exams-19-nov">Exams [7]</a>:</b> тества решаване на задачи на гимназиално ниво за природни и социални науки</li>
		<li ><b>MON:</b> включва изпити по предмети от 4 до 12 клас</li>
      </ul>

	  <p >Този набор от данни тества логическото разсъждаване, цялостните математически познания, езиковото разбиране и други умения на моделите.</p>
	  
	  <br><br>
	  <h2 >Резултати на BgGPT 9B и BgGPT 27B на български и английски език</h2>
	  
	  <div >
			<div 	style="display: flex; justify-content: center;align-items: center;max-width:100%;padding-top:50pt; padding-bottom:15pt;"><object type="image/svg+xml" style="max-width:100%;"data="/assets/img/bg_bench_bg_nov19.svg"></object></div>
			<div 	style="display: flex; justify-content: center;align-items: center;max-width:100%;padding-top:15pt; padding-bottom:50pt;"><object type="image/svg+xml" style="max-width:100%;" data="/assets/img/en_bench_bg_nov19.svg"></object></div>
      </div>
	  
	  <p >Графиките показват резултатите на BgGPT 9B и BgGPT 27B в сравнение с други големи отворени модели. 
	  Резултатите на български сочат, че уменията и на двата модела <b>превъзхождат тези на много по-големи такива</b> като Qwen 2.5 72B на Alibaba и Llama3.1 70B на Meta. 
	  Също така BgGPT 9B и 27B <b>значително надграждат над предишната версия на BgGPT</b> – <a href="https://huggingface.co/INSAIT-Institute/BgGPT-7B-Instruct-v0.2">BgGPT-7B-Instruct-v0.2</a>, базирана на Mistral-7B.</p>
      
	  <br><br>
	  <h2 >Резултати на BgGPT 2.6B на български и английски език</h2>
	  
	  <div >
			<div style="display: flex; justify-content: center;align-items: center;max-width:100%;padding-top:50pt; padding-bottom:15pt;"><object type="image/svg+xml" style="max-width:100%;"data="/assets/img/bg_bench_2b_bg_nov19.svg"></object></div>
			<div style="display: flex; justify-content: center;align-items: center;max-width:100%;padding-top:15pt; padding-bottom:50pt;"><object type="image/svg+xml" style="max-width:100%;"data="/assets/img/en_bench_2b_bg_nov19.svg"></object></div>
	  </div>

 	  <p >Освен BgGPT 9B и BgGPT 27B, INSAIT пуска и BgGPT 2.6B, малък езиков модел на български, базиран на Gemma-2 2.6B. 
	  На графиката показваме, че на нашия български набор от тестове, BgGPT 2.6B се справя <b>значително по-добре</b> от модели със същия размер като Phi 3.5 на Microsoft и Qwen 2.5 3B на Alibaba. 
	  Отново, както и с другите BgGPT модели, BgGPT 2.6B запазва способностите на Gemma 2 2.6B на английски език.</p>
	  
	  <br><br>
	  <h2 >Чат предпочитания на български език спрямо комерсиалните модели на OpenAI и Anthropic</h2>
	  
	  <div >
			<div style="display: flex; justify-content: center;align-items: center;max-width:100%;padding-top:50pt; padding-bottom:50pt;"><object type="image/svg+xml" style="max-width:100%;" data="/assets/img/chat_preference_media_bg_white.svg"></object></div>
	  </div>
	  
	  <p >Освен българските тестове, проверихме качеството на BgGPT 27B и по отношение на отговори на чат въпроси на около 100 различни теми. 
	  Резултатите показват, че той <b>значително надминава</b> по-малките варианти на моделите на Anthropic (Claude Haiku) и OpenAI (GPT-4o-mini) при работа на български език, 
	  и е <b>наравно с най-добрите комерсиални модели</b> като Claude Sonnet и GPT-4o <b>според самия GPT-4o</b>.</p>
      
	  <br><br>
	  <h2 >Препратки</h2>
	  
      <ol class="references">
		<li><a name="ref-emnlp-19-nov"><b>Mitigating Catastrophic Forgetting in Language Transfer via Model Merging</b>, Anton Alexandrov, Veselin Raychev, Mark Niklas Mueller, Ce Zhang, Martin Vechev, Kristina Toutanova. In Findings of the Association for Computational Linguistics: EMNLP 2024, pages 17167–17186, Miami, Florida, USA. Association for Computational Linguistics. <a href="https://aclanthology.org/2024.findings-emnlp.1000">https://aclanthology.org/2024.findings-emnlp.1000</a></a></li>
		<li><a name="ref-winograde-19-nov"><b>Winogrande: An adversarial winograd schema challenge at scale</b>, Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. Communications of the ACM, 64(9):99–106, 2021.</a></li>
        <li><a name="ref-hellaswag-19-nov"><b>Hellaswag: Can a machine really finish your sentence?</b>, Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. <a href="https://arxiv.org/abs/1905.07830">https://arxiv.org/abs/1905.07830</a></a></li>
        <li><a name="ref-arc-challenge-19-nov"><b>Think you have solved question answering? try arc, the ai2 reasoning challenge</b>, Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. <a href="https://arxiv.org/abs/1803.05457">https://arxiv.org/abs/1803.05457</a></a></li>
        <li><a name="ref-triviaqa-19-nov"><b>Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</b>, Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Zettlemoyer. <a href="https://arxiv.org/abs/1705.03551">https://arxiv.org/abs/1705.03551</a></a></li>
		<li><a name="ref-gsm8k-19-nov"><b>Training verifiers to solve math word problems</b>, Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. <a href="https://arxiv.org/abs/2110.14168">https://arxiv.org/abs/2110.14168</a></a></li>
        <li><a name="ref-exams-19-nov"><b>EXAMS: A multi-subject high school examinations dataset for cross-lingual and multilingual question answering</b>, Momchil Hardalov, Todor Mihaylov, Dimitrina Zlatkova, Yoan Dinkov, Ivan Koychev, and Preslav Nakov. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5427–5444, Online. Association for Computational Linguistics. <a href="https://aclanthology.org/2020.emnlp-main.438/">https://aclanthology.org/2020.emnlp-main.438/</a></a></li>
      </ol>
    </div>
	
    <div  class="container">
      <h1 style="margin-bottom:0;margin-top:4rem;" id="blogbg">Моделът зад приложението за чат BgGPT вече е публикуван</h1>
      <p class="date" style="margin-bottom:2rem;font-size:110%;">3 март 2024 г</p>
      <p>(Този текст е автоматично генериран от модела от <a href="/blogen">английската версия</a> на блога. <a href="#ref-trans">[*]</a>)</p>
      <p>В INSAIT сме развълнувани да пуснем BgGPT-7B-Instruct-v0.2, модела, който стои зад приложението за чат BgGPT: <a href="https://chat.bggpt.ai/">https://chat.bggpt.ai</a>. Този модел, част от серията BgGPT, е подобрена версия на тази, която пуснахме <a href="#blog-post-1">преди няколко седмици</a>. BgGPT-7B-Instruct-v0.2 все още е 7B модел, което го прави много бърз за генериране на текст и може да работи на повечето съвременни персонални компютри. Освен това идва с лиценз Apache 2.0, който е свободен и подходящ за търговски цели. Моделът се основава на Mistral-7B, но беше обучен върху значителни количества данни и комбиниран с други нововъведения (които ще бъдат публикувани в изследователски конференции), може да надмине много по-големи модели на задачи на български език. Обучението на BgGPT-7B-Instruct-v0.2 се финансира изцяло от частни средства и дарения. Моля, вижте блога ни за BgGPT-7B-Instruct-v0.1, който <a href="#blog-post-1">пуснахме по-рано.</a></p>
      <h2>Успешна история на BgGPT</h2>
      <p>През последните 2 седмици BgGPT-7B-Instruct-v0.1 вече е приет от различни компании, които са коментирали, че с малко часове работа и ниски разходи за изчислителни ресурси за фина настройка, той може да достигне производителността на GPT-4 на конкретна задача на български език.</p>
      <h2>Оценяване и бенчмаркове</h2>
      <p>Както при много други езикови модели, ние оценяваме на набор от стандартни превeдени на български тестове, както и английски тестове:</p>
      <ul>
        <li><a href="#ref-winograde-new">Winogrande предизвикателство [1]:</a> тестване на разбиране на света</li>
        <li><a href="#ref-hellaswag-new">Hellaswag [2]</a>: тестване на завършване на изречения</li>
        <li><a href="#ref-arc-challenge-new">ARC Challenge [3]</a>:тестване на логическо разсъждение</li>
        <li><a href="#ref-mmlu-new">MMLU [4]</a>: включва множество изборни въпроси от много области</li>
        <li><a href="#ref-mathqa-new">MathQA [5]</a>: тестване на математическо разсъждение</li>
        <li><a href="#ref-gsm8k-new">GSM8K [6]</a>: решаване на задачи с множество избора в гимназиалната математика</li>
        <li><a href="#ref-triviaqa-new">TriviaQA [7]</a>: тестване на знания за тривия</li>
        <li><a href="#ref-bgglue-new">bgGLUE [8]</a>: включва няколко задачи на български език</li>
      </ul>
      <p>Тези тестове тестват логическото разсъждение, математическите умения, знанията, разбирането на езика и други умения на модела.</p>
      <h2>Резултати от оценката</h2>
      
      <p>Следните графики показват представянето на BgGPT-7B-Instruct-v0.2. Той надминава моделите със същия размер на българските бенчмаркове, включително подобрява предишната версия на BgGPT-7B (BgGPT-7B-Instruct-v0.1). Той също така надмина по-големия Mixtral-8x7B-Instruct-v0.1 на българските бенчмаркове. Той запази своите английски умения и в някои отношения е сравним или по-добър от моделите на Gemma-7B на Google, Mistral-7B, Llama-7B и др.</p>
	  <div style="display: flex; justify-content: center;align-items: center;max-width:100%;padding-top:50pt; padding-bottom:15pt;"><object type="image/svg+xml" style="max-width:100%;" data="/assets/img/Bulgarian%20language%20skills%20on%20a%20set%20of%20LLM benchmarks v2 bg.svg"></object></div>
	  <div style="display: flex; justify-content: center;align-items: center;max-width:100%;padding-top:15pt; padding-bottom:15pt;"><object type="image/svg+xml" style="max-width:100%;"data="/assets/img/Other%20benchmarks v2 bg.svg"></object></div>
	  <div style="display: flex; justify-content: center;align-items: center;max-width:100%;padding-top:15pt; padding-bottom:50pt;"><object type="image/svg+xml" style="max-width:100%;"data="/assets/img/English%20language%20skills%20on%20a%20set%20of%20LLM benchmarks v2 bg.svg"></object></div>
      <h2>Изгледи</h2>
      <p>Въпреки че моделът е доста конкурентен на безплатните отворени модели и особено като се има предвид неговият размер, той все още не е на нивото на комерсиалните платени предложения. Въпреки това, дори на сегашното си ниво, той може да бъде полезен за много приложения.</p>
      <p id="ref-trans">[*] Преводът е извършен в 2 стъпки. Първо попитахме: “Преведи на български език следния текст:” и поставяме английската версия на текста без заглавието. След това в същия чат попитахме “Направи го да звучи по-точно”.</p>
      <h2>Препратки</h2>
      
      <ol class="references">
        <li><a name="ref-winograde-new">Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. Winogrande: An adversarial winograd schema challenge at scale. Communications of the ACM, 64(9):99–106, 2021.</li>
        <li><a name="ref-hellaswag-new">Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. Hellaswag: Can a machine really finish your sentence? <a href="https://arxiv.org/abs/1905.07830">https://arxiv.org/abs/1905.07830</a></li>
        <li><a name="ref-arc-challenge-new">Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning challenge. <a href="https://arxiv.org/abs/1803.05457">https://arxiv.org/abs/1803.05457</a></li>
        <li><a name="ref-mmlu-new">Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language understanding. <a href="https://arxiv.org/abs/2009.03300">https://arxiv.org/abs/2009.03300</a></li>
        <li><a name="ref-mathqa-new">Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh Hajishirzi. MathQA: Towards interpretable math word problem solving with operation-based formalisms <a href="https://arxiv.org/abs/1905.13319">https://arxiv.org/abs/1905.13319</a></li>
        <li><a name="ref-gsm8k-new">Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word problems. <a href="https://arxiv.org/abs/2110.14168">https://arxiv.org/abs/2110.14168</a></li>
        <li><a name="ref-triviaqa-new">Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Zettlemoyer. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. <a href="https://arxiv.org/abs/1705.03551">https://arxiv.org/abs/1705.03551</a></li>
        <li><a name="ref-bgglue-new">Momchil Hardalov, Pepa Atanasova, Todor Mihaylov, Galia Angelova, Kiril Simov, Petya Osenova, Veselin Stoyanov, Ivan Koychev, Preslav Nakov, and Dragomir Radev. bgGLUE: A Bulgarian general language understanding evaluation benchmark. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8733–8759 <a href="https://bgglue.github.io/">https://bgglue.github.io/</a></li>
      </ol>
    </div>
    <!-- Cloudflare Web Analytics -->
    <script defer src='https://static.cloudflareinsights.com/beacon.min.js' data-cf-beacon='{"token": "7392b251f9b044028a8606279c384767"}'></script>
    <!-- End Cloudflare Web Analytics -->
  </body>
</html>
